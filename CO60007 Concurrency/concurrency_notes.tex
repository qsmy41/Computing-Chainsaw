\documentclass[twocolumn,landscape,10pt]{article}
\usepackage[thinc]{esdiff} % for typesetting derivatives
\usepackage{amsthm} % provides an enhanced version of LaTex's \newtheorem command
\usepackage{mdframed} % framed environments that can split at page boundaries
\usepackage{enumitem} % bulletin points or other means of listing things
\usepackage{amssymb} % for AMS symbols
\usepackage{amsmath} % so as to use align
\usepackage{latexsym} % so as to use symbols like \leadsto
\usepackage{mathrsfs} % for using mathscr for char like operators
\usepackage{commath} % for using norm symbol
\usepackage{mathtools} % for using environments like dcases
\usepackage{authblk} % for writing affiliations
\usepackage{graphicx} % for importing images
\graphicspath{{./images/}} % for the path to images, also always put label behind captions
\usepackage{textcomp} % for using degree symbol
\usepackage{hyperref} % for clickable link in the pdf & customizable reference text
\usepackage[all]{hypcap} % for clickable link to images instead of caption
\usepackage[top=0.8in,bottom=0.8in,left=0.5in,right=0.5in]{geometry} % default is 1.5in
% \usepackage[left=0.4in, right=0.4in, top=0.8in, bottom=0.8in]{geometry}
\usepackage[title]{appendix} % for attaching appendix
\allowdisplaybreaks % allow page breaking in display maths, like align
\usepackage{xcolor} % for setting color of a block of text
\usepackage[normalem]{ulem} % for strikethrough text
% allow for more advanced table layout
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{siunitx}
% for adjusting caption settings
\usepackage{caption}
\captionsetup[table]{skip=10pt}

\theoremstyle{definition}
\mdfdefinestyle{defEnv}{%
  hidealllines=false,
  nobreak=true,
  innertopmargin=-1ex,
}

% The following is for writing block of code
\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

% setting of the thickness of the 4 lines of box
\setlength{\fboxrule}{2pt}

% Use the following to change code language and related settings
\lstset{language=C++,
  aboveskip=1mm,
  belowskip=1mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3,
  literate={~} {$\sim$}{1}
}

\pagestyle{headings}
\author{Lectured by Azalea Raad and Alastair Donaldson}
\title{The Theory \& Practice of Concurrent Programming}
\affil{Typed by Aris Zhu Yi Qing}
\begin{document}
\maketitle
\tableofcontents

\newpage
\section{Synchronisation Paradigms}

\subsection{Properties in Asynchronous computation}

\begin{enumerate}
    \item Safety
        \begin{itemize}
            \item Nothing bad happens ever
            \item If it is violated, it is done by a finite computation
        \end{itemize} 
    \item Liveness
        \begin{itemize}
            \item Something good happens eventually
            \item Cannot be violated by a finite computation
        \end{itemize} 
\end{enumerate} 

\subsection{Problems in Asynchronous computation}

\begin{enumerate}
    \item Mutual Exclusion (Safety)
        \begin{itemize}
            \item \textbf{cannot} be solved by transient communication or
                interrupts
            \item \textbf{can} be solved by shared variables that can be
                read or written
        \end{itemize} 
    \item No Deadlock (Liveness): Some event $A$ eventually happens.
\end{enumerate} 

\subsection{Protocols in Asynchronous computation}

\begin{enumerate}
    \item Flag Protocol (from B's perspective):
        \begin{itemize}
            \item Raise flag
            \item While A's flag is up
                \begin{itemize}
                    \item Lower flag
                    \item Wait for A's flag to go down
                    \item Raise flag
                \end{itemize} 
            \item Do something
            \item Lower flag
        \end{itemize} 
    \item Producer/Consumer:
        \begin{itemize}
            \item For A(producer), while flag is up wait. So when flag becomes down,
                do something, then raise the flag.
            \item For B(consumer), while flag is down, wait. So when flag
                becomes up, do something, then put down the flag.
        \end{itemize} 
    \item Readers/Writers:
        \begin{itemize}
            \item Each thread \texttt{i} has \texttt{size[i]} counter. Only it
                increments or decrements.
            \item To get object's size, a thread reads a ``snapshot'' of all
                counters.
            \item This eliminates the bottleneck of ``having exclusive access to
                the common counter''.
        \end{itemize} 
\end{enumerate} 

\subsection{Performance Measurement}

Amdahl's law:
\[
    \text{Speedup} = \frac{\text{1-thread execution time}}
    {n\text{-thread execution time}}
    = \frac{1}{1-p+\frac{p}{n}},
\]
where $p$ is the fraction of the algorithm having parallel execution, and $n$ is
the number of threads.

\newpage
\section{Concurrent Semantics}

\subsection{Notation}

\begin{itemize}
    \item\makebox[2cm]{$x,y,z,\ldots$\hfill} shared memory locations
    \item\makebox[2cm]{$a,b,c,\ldots$\hfill} private registers
    \item\makebox[2cm]{$E,E_1,\ldots$\hfill} expressions over values
                (integers) and registers
    \item\makebox[2cm]{$a:=x$\hfill} \textbf{read} from location $x$ into
            register $a$
    \item\makebox[2cm]{$x:=a$\hfill} \textbf{write} contents of register $a$ to
            location $x$
    \item\makebox[2cm]{$a:=E$\hfill} \textbf{assignment}: compute $E$ and write
            it to $a$
\end{itemize} 

\subsection{ConWhile concurrent programming language}

\begin{align*}
    B\in \text{Bool}\quad::=& \quad\texttt{true} \,|\, \texttt{false} \,|\, \ldots \\
    E\in \text{Exp}\quad::=&\quad\ldots \,|\, E + E \,|\, \ldots \\
    C\in \text{Com}\quad::=&\quad
    \begin{aligned}[t]
        & a := E & \text{assignment} \\
        & |\,a := x & \text{(memory) read} \\
        & |\,x := a & \text{(memory) write} \\
        & |\,a := \texttt{CAS}(x,E,E)\,|\,\texttt{FAA}(x,E) & \text{(memory) RMWs} \\
        & |\,\texttt{skip}\,|\,C;\;C\,|\,\texttt{while}\;B\;\texttt{do}\;C & \\
        & |\,\texttt{if}\;B\;\texttt{then}\;C\;\texttt{else}\;C, & \\
        & |\,\texttt{mfence} & \text{memory fence (TSO only)} \\
    \end{aligned}
\end{align*} 
where \texttt{FAA} (fetchAndAdd) is considered \emph{weak}
RMW because it enables synchronisation between \underline{two} threads only,
whereas \texttt{CAS} (compareAndSet) is considered \emph{strong} RMW because it
enables synchronisation among an \underline{arbitrary} number of threads.


\subsection{Sequential Consistency (SC)}

Also called \underline{Interleaving Semantics}. 
The instructions of each thread are executed in order.
Instructions of different threads interleave arbitrarily.

\begin{itemize}
    \item We model ConWhile \underline{concurrent program} as a map 
        from thread identifiers ($\tau\in\text{Tid}$) to sequential commands:
        \[
            P\in\text{Prog}\triangleq\text{Tid}\rightarrow\text{Com}.
        \]
    \item We use $\parallel$ notation for concurrent programs and write 
        \[
            C_1\parallel C_2\parallel \ldots\parallel C_n
        \]
        for the $n$-threaded program $P$ with
        \[
            \text{dom}(P)=\left\{\tau_1,\ldots,\tau_n\right\}
        \]
        and
        $P(\tau_i)=C_i$ for $i\in\left\{1,\ldots,n\right\}$.
    \item For instance, we write
        $\text{dom}(P_{\text{sb}})=\left\{\tau_1,\tau_2\right\}$,
        with $P_{\text{sb}}(\tau_1)=x:=1;a:=y;$ and
        $P_{\text{sb}}(\tau_2)=y:=1;b:=x;$, therefore
        \[
            P_{\text{sb}}\quad\triangleq\quad
            x:=1;a:=y;\;\parallel\;y:=1;b:=x;\,.
        \]
    \item We model the \underline{shared memory} as a map from locations to
        values:
        \[
            M\in\text{Mem}\triangleq\text{Loc}\rightarrow\text{Val},
        \]
        where Val denotes the set of all values, including integer and Boolean
        values.
    \item We define \underline{store} as a map from registers to values:
        \[
            s\in\text{Store}\triangleq\text{Reg}\rightarrow\text{Val}.
        \]
    \item We define \underline{store map} associating each thread with its
        private store:
        \[
            S\in\text{SMap}\triangleq\text{Tid}\rightarrow\text{Store}.
        \]
    \item An \underline{SC configuration} is a triple, $(P,S,M)$, comprising a
        program $P$ to be executed, the store map $S$, and the shared memory
        $M$.
    \item The \underline{program transitions} describe the steps in program
        executions.
    \item The \underline{storage transitions} describe how instructions interact
        with the storage (memory) system.
    \item An \underline{SC transition label}, $l\in\text{Lab}$, may be:
        \begin{itemize}
            \item the \emph{empty} label $\epsilon$ to denote a silent transition
            \item a \emph{read} label $(\text{R},x,v)$ to denote reading value $v$ from
                memory location $x$
            \item a \emph{write} label $(\text{W},x,v)$ to denote writing value $v$ to
                memory location $x$
            \item a \emph{successful RMW} label $(\text{RMW},x,v_0,v_n)$ to
                denote updating the value of location $x$ to $v_n$ when the old
                value of $x$ is $v_0$
            \item a \emph{failed RMW} label $(\text{RMW},x,v_0,\bot)$ to denote
                a failed \texttt{CAS} instruction where the old value of $x$
                does not match $v_0$.
        \end{itemize} 
    \item Assume that store $s$ has the mapping for all Boolean expressions $B$
        and program expressions $E$.
    \item SC Sequential Transitions (Familiar Cases):
        \[
            \frac{C_1,s\xrightarrow{l}_c C_1',s'}{C_1;C_2,s\xrightarrow{l}_c
            C_1';C_2,s'} \qquad
            \frac{}{\texttt{skip};C,s\xrightarrow{\epsilon}_c C,s}
        \]
        \[
            \frac{s(B)=\texttt{true}}{\texttt{if}\,B\,\texttt{then}\,C_1\,\texttt{else}\,C_2,s\xrightarrow{\epsilon}_c
            C_1,s} \qquad
            \frac{s(B)=\texttt{false}}{\texttt{if}\,B\,\texttt{then}\,C_1\,\texttt{else}\,C_2,s\xrightarrow{\epsilon}_c
            C_2,s} \qquad
        \]
        \[
            \frac{}{\texttt{while}\,B\,\texttt{do}\,C,s\xrightarrow{\epsilon}_c
            \texttt{if}\,B\,\texttt{then}\,(C;\,\texttt{while}\,B\,\texttt{do}\,C)\,
            \texttt{else}\,\texttt{skip}, s}
        \]
        \[
            \frac{s(E)=v\qquad s'=s[a\mapsto
            v]}{a:=E,s\xrightarrow{\epsilon}_c\texttt{skip},s'}
        \]
    \item SC Sequential Transitions (New Cases):
        \begin{align*}
            x:=a\qquad& \frac{s(a)=v}
            {x:=a,s\xrightarrow{(\text{W},x,v)}_c\texttt{skip},s} \\[0.5em]
            a:=x\qquad& \frac{s'=s[a\mapsto v]}
            {a:=x,s\xrightarrow{(\text{R},x,v)}_c\texttt{skip},s'} \\[0.5em]
            \texttt{FAA}(x,E)\qquad& \frac{s(E)=v\qquad v_n=v_0+v}
            {\texttt{FAA}(x,E),s\xrightarrow{(\text{RMW},x,v_0,v_n)}_c\texttt{skip},s}\\[0.5em]
            \texttt{CAS}(x,E_0,E_n)\text{ (success)}\qquad& 
            \frac{s(E_0)=v_0\qquad s(E_n)=v_n\qquad s'=s[a\mapsto 1]}
            {a:=\texttt{CAS}(x,E_0,E_n),s\xrightarrow{(\text{RMW},x,v_0,v_n)}_c 
            \texttt{skip},s'}\\[0.5em]
            \texttt{CAS}(x,E_0,E_n)\text{ (failure)}\qquad& 
            \frac{s(E_0)=v_0\qquad v\neq v_0\qquad s'=s[a\mapsto 0]}
            {a:=\texttt{CAS}(x,E_0,E_n),s\xrightarrow{(\text{RMW},x,v,\bot)}_c 
            \texttt{skip},s'}
        \end{align*} 
    \item SC (Concurrent) Program Transitions:
        \[
            \frac{P(\tau)=C\quad S(\tau)=s\quad C,s\xrightarrow{l}_c C',s'
            \quad P'=P[\tau\mapsto C']\quad S'=S[\tau\mapsto s']}
            {P, S\xrightarrow{\tau:l}_p P',S'}
        \]
    \item SC Storage Transitions (of the form $M\xrightarrow{\tau:l}_m M'$):
        \begin{align*}
            \text{Read}\qquad&
            \frac{M(x)=v}{M\xrightarrow{\tau:(\text{R},x,v)}_m M}\\[0.5em]
            \text{Write}\qquad&
            \frac{M'=M[x\mapsto v]}{M\xrightarrow{\tau:(\text{W},x,v)}_m M'}\\[0.5em]
            \text{RMW},x,v_0,v_n\qquad&
            \frac{M(x)=v_0\qquad M'=M[x\mapsto v_n]}
            {M\xrightarrow{\tau:(\text{RMW},x,v_0,v_n)}_m M'}\\[0.5em]
            \text{RMW},x,v,\bot\qquad&
            \frac{M(x)=v}{M\xrightarrow{\tau:(\text{RMW},x,v,\bot)}_m M'}
        \end{align*} 
    \item SC Operational Semantics:
        \begin{align*}
            \text{silent transition}\qquad&
            \frac{P,S\xrightarrow{\tau:\epsilon}_p P',S'}{P,S,M\rightarrow P',S',M}\\[0.5em]
            \shortstack{\text{both program and storage systems 
            \\take the same transition}}\qquad&
            \frac{P,S\xrightarrow{\tau:l}_p P',S'\qquad M\xrightarrow{\tau:l}_m M'}
            {P,S,M\rightarrow P',S',M'}
        \end{align*} 
    \item We write $\rightarrow^{*}$ for the reflexive, transitive closure of
        $\rightarrow$.
    \item SC Traces
        \begin{itemize}
            \item The initial memory, $M_0\triangleq\lambda x.0$.
            \item The initial store, $s_0\triangleq\lambda a.0$.
            \item The initial store map, $S_0\triangleq\lambda\tau.s_0$.
            \item The terminated program,
                $P_{\texttt{skip}}\triangleq\lambda\tau.\texttt{skip}$.
            \item Given a program $P$, an \textbf{SC-trace} of $P$ is an
                evaluation path s.t.
                \[
                    P,S_0,M_0\rightarrow^*P_{\texttt{skip}},S,M
                \]
                where the pair $(S,M)$ denotes an \textbf{SC-outcome}.
        \end{itemize} 
    \item SC is \textbf{neither} deterministic \textbf{nor} confluent.
\end{itemize} 

\subsection{Total Store Ordering (TSO)}

$\text{TSO}=\text{SC}+\text{write-read reordering}$. This allows the weak 
Store Buffering (SB) behaviour. We can stop the reordering by using memory
fences or RMWs, which can impede performance.

\begin{itemize}
    \item In addition to the \underline{concurrent program}, \underline{shared memory}, 
        \underline{store}, and \underline{store map} defined in the SC,
        we have an addition \underline{buffer} associating each thread,
        modelled as a FIFO sequence of (delayed) write label:
        \[
            b\in\text{Buff}\triangleq\text{Seq}\left\langle\text{WLab}\right\rangle
            \qquad\text{WLab}\triangleq\left\{(\text{W},x,v)\,|\,x\in\text{Loc}\wedge
            v\in\text{Val}\right\}.
        \]
        That is, a buffer entry $(\text{W},x,v)$ denotes a delayed write on $x$
        with value $v$.
    \item We define \underline{buffer map} associating each thread with its
        private buffer:
        \[
            B\in\text{BMap}\triangleq\text{Tid}\rightarrow\text{Buff}.
        \]
    \item An \underline{TSO configuration} is a quadruple, $(P,S,M,B)$,
        comprising the program $P$ to be executed, the store map $S$, the shared
        memory $M$ and the buffer map $B$.
    \item A \underline{TSO transition label}, $l\in\text{Lab}$, may be:
        \begin{itemize}
            \item an SC label, namely $\epsilon$, $(\text{R},x,v)$,
                $(\text{W},x,v)$, $(\text{RMW},x,v_0,v_n)$,
                $(\text{RMW},x,v_0,\bot)$
            \item a \emph{memory fence} label \texttt{MF} for executing an
                \texttt{mfence}.
        \end{itemize} 
    \item TSO Sequential Transition (New case):
        \[
            \texttt{mfence} \qquad \frac{}
            {\texttt{mfence},s\xrightarrow{\texttt{MF}}_c\texttt{skip},s}
        \]
    \item TSO Program Transitions: the same as SC Program Transition.
    \item TSO Storage Transitions 
        (of the form $M,B\xrightarrow{\tau:l}_m M',B'$):
        \begin{align*}
            \text{Read}\qquad&
            \begin{aligned}
                &\frac{B(\tau)=b\qquad\texttt{get}(\text{M},b,x)=v}
                {M,B\xrightarrow{\tau:(\text{R},x,v)}_m M,B},\text{ where}\\[0.5em]
                & \texttt{get}(\text{M},b,x)\triangleq
                \begin{cases}
                    v & \text{if }\exists
                    b_1,b_2\text{ s.t. }b=b_1.(\text{W},x,v).b_2\\
                      &\quad\wedge\neg\exists
                    v'\text{ s.t. }(\text{W},x,v')\in b_2\\
                    M(x) & \text{otherwise}
                \end{cases} 
            \end{aligned}\\[1em]
            \text{Write}\qquad&
            \frac{B(\tau)=b\qquad b'=b.(\text{W},x,v)\qquad B'=B[\tau\mapsto b']}
            {M,B\xrightarrow{\tau:(\text{W},x,v)}_m M, B'}\\[0.5em]
            \text{Memory Fence}\qquad&
            \frac{B(\tau)=\emptyset}{M,B\xrightarrow{\tau:\texttt{MF}}_c M,B}\\[0.5em]
            \text{RMW},x,v_0,v_n\qquad&
            \frac{B(\tau)=\emptyset\qquad M(x)=v_0\qquad M'=M[x\mapsto v_n]}
            {M,B\xrightarrow{\tau:(\text{RMW},x,v_0,v_n)}_m M',B}\\[0.5em]
            \text{RMW},x,v,\bot\qquad&
            \frac{B(\tau)=\emptyset\qquad M(x)=v}
            {M,B\xrightarrow{\tau:(\text{RMW},x,v,\bot)}_m M,B}\\[0.5em]
            \text{unbuffer}\qquad&
            \frac{B(\tau)=(\text{W},x,v).b\quad M'=M[x\mapsto v]\quad
            B'=B[\tau\mapsto b]}
            {M,B\xrightarrow{\tau:\epsilon}_m M',B'}
        \end{align*} 
    \item TSO Operational Semantics:
        \begin{align*}
            \text{silent transition in program}\qquad&
            \frac{P,S\xrightarrow{\tau:\epsilon}_p P',S'}
            {P,S,M,B\rightarrow P',S',M,B}\\[0.5em]
            \text{silent transition in storage system}\qquad&
            \frac{M,B\xrightarrow{\tau:\epsilon}_m M',B'}
            {P,S,M,B\rightarrow P,S,M',B'}\\[0.5em]
            \shortstack{\text{both program and storage system 
            \\take the same transition}}\qquad&
            \frac{P,S\xrightarrow{\tau:\epsilon}_p P',S'\quad 
            M,B\xrightarrow{\tau:\epsilon}_m M',B'}
            {P,S,M,B\rightarrow P',S',M',B'}
        \end{align*} 
    \item We write $\rightarrow^{*}$ for the reflexive, transitive closure of
        $\rightarrow$, the same as the SC's.
    \item TSO Traces
        \begin{itemize}
            \item In addition to the initial memory, initial store, initial
                store map, and the terminated program defined in SC, we have the
                initial buffer map, $B_0\triangleq\lambda\tau.\emptyset$.
            \item Given a program $P$, the initial TSO-configuration of $P$ is
                $(P,S_0,M_0,B_0)$.
            \item Given a program $P$, a \textbf{TSO-trace} of $P$ is an
                evaluation path s.t.
                \[
                    P,S_0,M_0,B_0\rightarrow^* P_\texttt{skip},S,M,B_0
                \]
                where the pair $(S,M)$ denotes a \textbf{TSO-outcome}.
        \end{itemize} 
    \item TSO is also \textbf{neither} deterministic \textbf{nor} confluent.
\end{itemize}

\newpage
\section{Linearization}

\subsection{Notation}

\begin{itemize}
    \item\makebox[2cm]{\texttt{A q.enq(x)}\hfill} Invocation:
        $\left\langle\text{thread}\right\rangle$
        $\left\langle\text{object}\right\rangle$.$\left\langle\text{method}\right\rangle$($\left\langle\text{arguments}\right\rangle$)
    \item\makebox[2cm]{\texttt{A q:void}\hfill} Response:
        $\left\langle\text{thread}\right\rangle$
        $\left\langle\text{object}\right\rangle$:$\left\langle\text{result}\right\rangle$
    \item\makebox[2cm]{$H$\hfill} Sequence of invocations and responses,
        which looks like:
        \[
            H = \quad\begin{align}
                &\texttt{A q.enq(3)} \\
                &\texttt{A q:void} \\
                &\texttt{A q.enq(5)} \\
                &\textcolor{teal}{\texttt{B p.enq(4)}} \\
                &\textcolor{teal}{\texttt{B p:void}} \\
                &\textcolor{teal}{\texttt{B q.deq()}} \\
                &\textcolor{teal}{\texttt{B q:3}} \\
            \end{align} 
        \]
\end{itemize} 

\subsection{Definitions}

\begin{itemize}
    \item Invocation and response \underline{match} if thread and object names
        agree
    \item \underline{Object Projections}:
        \[
            H = \quad\begin{align}
                &\texttt{A q.enq(3)} \\
                &\texttt{A q:void} \\
                &\texttt{A q.enq(5)} \\
                &\textcolor{teal}{\texttt{B p.enq(4)}} \\
                &\textcolor{teal}{\texttt{B p:void}} \\
                &\textcolor{teal}{\texttt{B q.deq()}} \\
                &\textcolor{teal}{\texttt{B q:3}} \\
            \end{align} 
            \qquad\Longrightarrow\qquad
            H|q = \quad\begin{align}
                &\texttt{A q.enq(3)} \\
                &\texttt{A q:void} \\
                &\texttt{A q.enq(5)} \\
                \\
                \\
                &\textcolor{teal}{\texttt{B q.deq()}} \\
                &\textcolor{teal}{\texttt{B q:3}} \\
            \end{align} 
        \]
    \item \underline{Thread Projections}:
        \[
            H = \quad\begin{align}
                &\texttt{A q.enq(3)} \\
                &\texttt{A q:void} \\
                &\texttt{A q.enq(5)} \\
                &\textcolor{teal}{\texttt{B p.enq(4)}} \\
                &\textcolor{teal}{\texttt{B p:void}} \\
                &\textcolor{teal}{\texttt{B q.deq()}} \\
                &\textcolor{teal}{\texttt{B q:3}} \\
            \end{align} 
            \qquad\Longrightarrow\qquad
            H|B = \quad\begin{align}
                \\
                \\
                \\
                &\textcolor{teal}{\texttt{B p.enq(4)}} \\
                &\textcolor{teal}{\texttt{B p:void}} \\
                &\textcolor{teal}{\texttt{B q.deq()}} \\
                &\textcolor{teal}{\texttt{B q:3}} \\
            \end{align} 
        \]
    \item An invocation is \underline{pending} if it has no matching response.
        It may or may not have taken effect.
    \item A \underline{complete subhistory} is a history where pending
        invocations are discarded.
    \item A \underline{sequential history} is one whose invocations are always
        \emph{immediately} followed by their respective responses.
    \item A \underline{well-formed} history is one whose per-thread projections 
        are sequential.
    \item \underline{Equivalent histories} are those which have the same
        threads and their per-thread projections are the same.
    \item A \underline{sequential specification} is some way of telling whether
        a single-thread, single-object history, is legal.
    \item A sequential history $H$ is \underline{legal} if for every object $x$,
        $H|x$ is in the sequential specification for $x$.
    \item A method call \underline{precedes} another if its response event 
        precedes the other's invocation event.
        \begin{itemize}
            \item Given history $H$, method executions $m_0, m_1$ in $H$,
                we say
                \[
                    m_0 \rightarrow_H m_1
                \]
                if $m_0$ precedes $m_1$.
            \item The above relation is a \underline{partial} order. It is
                \underline{total} order if $H$ is sequential.
        \end{itemize} 
    \item History $H$ is \textbf{\underline{linearizable}} if
        \begin{itemize}
            \item it can be extended to a \emph{complete} history $G$
            \item $G$ is equivalent to a \emph{legal sequential} history $S$,
                where $\pmb{\rightarrow_G}\,\subseteq\,\pmb{\rightarrow_S}$.
        \end{itemize} 
    \item Remarks on linearizability:
        \begin{itemize}
            \item For pending invocations which took effect, keep them, and
                discard the rest.
            \item $\pmb{\rightarrow_H}$ stands for the set of all precedence
                relations in history $H$.
            \item Focus on \underline{total}(defined in every state) method.
            \item Partial methods are equivalent to thread blocking, and
                blocking is unrelated to synchronisation.
            \item We can identify ``\underline{linearization points}'' 
                to help check if executions are linearizable. The point
                \begin{itemize}
                    \item is between invocation and response events
                    \item correspond to the effect of the call
                    \item ``justify'' the whole execution
                \end{itemize} 
        \end{itemize} 
    \item \textbf{Composability Theorem}:
        \[
            \text{History $H$ is linearizable $\iff\,\forall$ object $x$, $H|x$ is
            linearizable.}
        \]
    \item History $H$ is \textbf{\underline{sequentially consistent (SC)}} if
        \begin{itemize}
            \item it can be extended to a \emph{complete} history $G$
            \item $G$ is equivalent to a \emph{legal sequential} history $S$,
                \sout{where $\pmb{\rightarrow_G}\,\subseteq\,\pmb{\rightarrow_S}$}.
        \end{itemize} 
    \item Remarks on SC:
        \begin{itemize}
            \item \emph{Cannot} re-order operations done by the same thread
            \item \emph{Can} re-order non-overlapping operations done by
                different threads
            \item SC is too strong for hardware architecture, 
                yet too weak for software \emph{specification}.
            \item SC is useful for abstracting software \emph{implementation}.
        \end{itemize} 
    \item (non-examinable) Progress conditions (from least ideal to most ideal):
        \begin{itemize}
            \item Deadlock-free: \emph{some} thread trying to acquire the lock
                eventually succeeds.
            \item Starvation-free: \emph{every} thread trying to acquire the lock
                eventually succeeds.
            \item Lock-free: \emph{some} thread calling a method
                eventually returns.
            \item Wait-free: \emph{every} thread calling a method
                eventually returns.
        \end{itemize} 
\end{itemize} 

\newpage
\section{Concurrency in C++}

\subsection{Threads and Locks}

\subsubsection{\texttt{std::thread}}

\begin{lstlisting}[C++]
#include <thread>
#include <functional> // Provides std::ref

// approach 1
void Foo(int by_value, std::string& by_reference) { ... }
std::string world = "World";
std::thread t1(Foo, 1, std::ref(world));

// approach 2
int y, x = 3;
std::thread t2([x, &y]() -> void {
    y = x * 42;
});

t1.join();
t2.join();
\end{lstlisting}

\subsubsection{\texttt{std::mutex}}

\begin{lstlisting}[C++]
#include <mutex>

std::mutex mutex_;
mutex_.lock();
mutex_.unlock();
\end{lstlisting}

\subsubsection{\texttt{std::scoped\_lock<std::mutex>}}

\begin{lstlisting}[C++]
class ScopedLock {
public:
    explicit ScopedLock(std::mutex &mutex) : mutex_(mutex) {
        mutex_.lock();
    }

    ~ScopedLock() {
        mutex_.unlock();
    }

private:
    std::mutex &mutex_;
}
\end{lstlisting}

\subsubsection{\texttt{std::unique\_lock<std::mutex>}}

\begin{itemize}
    \item constructed with one mutex
    \item locks mutex on construction (default), or deferred locking:
        \\\texttt{std::unique\_lock<std::mutex> lock(mutex\_, std::defer\_lock);}
    \item allows unlocking and relocking
    \item unlocks mutex on destruction if still held
    \item supports transfer of ownership to a distinct \emph{unique} 
        owner via \texttt{std::move}.
\end{itemize} 

\subsubsection{\texttt{std::condition\_variable}}

\begin{lstlisting}[C++]
#include <condition_variable>

std::condition_variable condition_;
condition_.notify_one();
condition_.notify_all();

std::unique_lock<std::mutex> lock(mutex_);
/* Assuming that the thread has locked the mutex:
 * 1. return if predicate holds (continue executing code after wait())
 * 2. release lock
 * 3. block until another thread signals (via notify_one or norify_all)
 * 4. acquire lock, then return to step 1
 */
condition_.wait(lock, [...]() -> bool {
    return ...;
});
\end{lstlisting}

\subsection{Atomics}

\subsubsection{Operations on \texttt{std::atomic<T>}}

\begin{itemize}
    \item \texttt{store(x)}: store value \texttt{x} of type \texttt{T}
    \item \texttt{load()}: yields value of type \texttt{T}
    \item \texttt{exchange(x)}: store \texttt{x} and return old value
    \item \texttt{compare\_exchange\_strong(expected, desired)}:
        \begin{itemize}
            \item \underline{Success}: old value is \texttt{expected}, store
                \texttt{desired}, return \texttt{true}
            \item \underline{Failure}: old value not \texttt{expected}, store
                old value to \texttt{expected}, return \texttt{false}
        \end{itemize} 
    \item \texttt{compare\_exchange\_weak(expected, desired)}:
        the same as the previous operation,
        except that it allows to fail spuriously, i.e.\ fail even if old value
        is \texttt{expected}.
\end{itemize} 

\subsubsection{(RMW) Operations on \texttt{std::atomic<integral\_type>}}

\begin{itemize}
    \item \texttt{fetch\_add(x)}: replace the value with (value + \texttt{x}),
        return old value.
    \item \texttt{fetch\_sub(x)}: similar
    \item \texttt{fetch\_and(x)}: similar
    \item \texttt{fetch\_or(x)}: similar
    \item \texttt{fetch\_xor(x)}: similar
\end{itemize} 

\subsubsection{Memory ordering}
\begin{itemize}
    \item Atomics are sequentially consistent by default.
    \item \textbf{Relaxed memory order} only guarantee sequential consistency
        \emph{per location}.
    \item
        \textbf{Acquire semantics} prevents memory reordering of the
        read-acquire with any read or write operation that 
        \underline{\emph{follows}} it in program order,
        i.e.\ all memory operations after read-acquire happen after
        read-acquire.
    \item
        \textbf{Release semantics} prevents memory reordering of the
        write-release with any read or write operation that
        \underline{\emph{precedes}} it in program order.
        i.e.\ all memory operations before write-release happen before
        write-release.
    \item In fact, acquiring a lock implies acquire semantics, releasing a lock
        implies release semantics!
    \item Please refer to
        \href{https://preshing.com/20120913/acquire-and-release-semantics}{this}
        for detailed explanation and discussion on acquire-release semantics.
    \item various atomics semantics:
        \begin{itemize}
            \item \texttt{std::memory\_order\_seq\_cst}
            \item \texttt{std::memory\_order\_relaxed}
            \item \texttt{std::memory\_order\_release}
            \item \texttt{std::memory\_order\_acquire}
            \item \texttt{std::memory\_order\_acq\_rel}
        \end{itemize} 
    \item example code snippet:
        \texttt{x.fetch\_add(1, std::memory\_order\_acq\_rel);}
\end{itemize} 

\subsection{SpinLock}

\subsubsection{Local spinning}
\begin{lstlisting}[C++]
void Lock() { 
    // lock_bit_ is a boolean, represents if lock is acquired
    while (lock_bit_.exchange(true)) {
        // Did not get the lock -- spin until it's free
        while (lock_bit_.load()) {
            // someone still holds the lock
        }
        // observed the lock being free -- try to grab it
    }
}
\end{lstlisting} 
\smallskip
\subsubsection{Active backoff}
\begin{lstlisting}[C++]
void Lock() { 
    while (lock_bit_.exchange(true)) {
        // Did not get the lock -- spin until it's free
        do {
            for (volatile size_t i = 0; i < 100; i++) {
                // Do nothing
            }
        } while (lock_bit_.load());
        // observed the lock being free -- try to grab it
    }
}
\end{lstlisting} 
\smallskip
\subsubsection{Passive backoff}
\begin{lstlisting}[C++]
#include <emmintrin.h>
void Lock() { 
    while (lock_bit_.exchange(true)) {
        // Did not get the lock -- spin until it's free
        do {
            for (size_t i = 0; i < 4; i++) {
                // Tell hardware that we are spinning
                _mm_pause();
            }
        } while (lock_bit_.load());
        // observed the lock being free -- try to grab it
    }
}
\end{lstlisting} 
\smallskip
\subsubsection{Exponential backoff}
\begin{lstlisting}[C++]
void Lock() { 
    const size_t kMinBackoffIterations = 4u;
    const size_t kMaxBackoffIterations = 1u << 10u;
    size_t backoff_iterations = kMinBackoffIterations;
    while (lock_bit_.exchange(true)) {
        // Did not get the lock -- spin until it's free
        do {
            for (size_t i = 0; i < backoff_iterations; i++) {
                // Tell hardware that we are spinning
                _mm_pause();
            }
            backoff_iterations = 
                std::min(backoff_iterations << 1, kMaxBackoffIterations);
        } while (lock_bit_.load());
        // observed the lock being free -- try to grab it
    }
}
\end{lstlisting} 
\smallskip
\subsubsection{Ticket lock (Fairness)}
\begin{lstlisting}[C++]
class SpinLockTicket {
public:
    SpinLockTicket() : next_ticket_(0), now_serving_(0) {}

    void Lock() {
        const auto ticket = next_ticket_.fetch_add(1);
        while (now_serving_.load() != ticket) {
            _mm_pause();
        }
    }

    void Unlock() {
        now_serving_.store(now_serving_.load() + 1);
    }

private:
    std::atomic<size_t> next_ticket_;
    std::atomic<size_t> now_serving_;
}
\end{lstlisting} 
\medskip
\subsubsection{Comments}
\begin{itemize}
    \item \texttt{lock\_bit\_.exchange(true)}: 
        performs Test-And-Set(TAS) operation.
        \begin{itemize}
            \item It enters the memory to set \texttt{lock\_bit\_} to
                \texttt{true}, and return its old value
            \item It also thrashes the cached values (\textbf{cache thrashing})
                for other cores, i.e.\
                the cached value of \texttt{lock\_bit\_} is invalidated for
                other cores. This leads to memory access 
                when other cores load the value of \texttt{lock\_bit\_} 
                and cache the value thereafter.
        \end{itemize} 
    \item \texttt{lock\_bit\_.load()}:
        loads the value of \texttt{lock\_bit\_}.
        \begin{itemize}
            \item If cached value of \texttt{lock\_bit\_} is valid, load the
                value from cache.
            \item Otherwise load the value from memory.
        \end{itemize} 
    \item \texttt{volatile}:
        a hint to the implementation to avoid aggressive optimisation involving
        the object.
    \item \texttt{\_mm\_pause()}:
        calls x86's underlying processor instructions for hinting that program
        is spinning.
        \begin{itemize}
            \item Allows the processor to ``do nothing'' more efficiently,
                thereby reducing energy consumption.
            \item Does \emph{not} include OS context switch.
        \end{itemize} 
\end{itemize} 

\end{document}
